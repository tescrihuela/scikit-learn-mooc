{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning\n",
    "\n",
    "In the previous section, we did not discuss the parameters of random forest\n",
    "and gradient-boosting. However, there are a couple of things to keep in mind\n",
    "when setting these.\n",
    "\n",
    "This notebook gives crucial information regarding how to set the\n",
    "hyperparameters of both random forest and gradient boosting decision tree\n",
    "models.\n",
    "\n",
    "<div class=\"admonition caution alert alert-warning\">\n",
    "<p class=\"first admonition-title\" style=\"font-weight: bold;\">Caution!</p>\n",
    "<p class=\"last\">For the sake of clarity, no cross-validation will be used to estimate the\n",
    "testing error. We are only showing the effect of the parameters\n",
    "on the validation set of what should be the inner cross-validation.</p>\n",
    "</div>\n",
    "\n",
    "## Random forest\n",
    "\n",
    "The main parameter to tune for random forest is the `n_estimators` parameter.\n",
    "In general, the more trees in the forest, the better the statistical\n",
    "performance will be. However, it will slow down the fitting and prediction\n",
    "time. The goal is to balance computing time and statistical performance when\n",
    "setting the number of estimators when putting such learner in production.\n",
    "\n",
    "The `max_depth` parameter could also be tuned. Sometimes, there is no need\n",
    "to have fully grown trees. However, be aware that with random forest, trees\n",
    "are generally deep since we are seeking to overfit the learners on the\n",
    "bootstrap samples because this will be mitigated by combining them.\n",
    "Assembling underfitted trees (i.e. shallow trees) might also lead to an\n",
    "underfitted forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data, target = fetch_california_housing(return_X_y=True, as_frame=True)\n",
    "target *= 100  # rescale the target in k$\n",
    "data_train, data_test, target_train, target_test = train_test_split(\n",
    "    data, target, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.114995      0.009190         0.009202        0.000751   \n",
       "1       0.214003      0.006692         0.011596        0.001356   \n",
       "2       0.315399      0.013982         0.012401        0.001020   \n",
       "3       0.165599      0.006651         0.008600        0.000490   \n",
       "4       0.329000      0.007459         0.010801        0.000747   \n",
       "5       0.503401      0.015906         0.013999        0.001266   \n",
       "6       0.479598      0.012811         0.011999        0.001097   \n",
       "7       0.919997      0.010991         0.017801        0.000750   \n",
       "8       1.366801      0.035571         0.023400        0.000800   \n",
       "\n",
       "  param_max_depth param_n_estimators                                   params  \\\n",
       "0               3                 10     {'max_depth': 3, 'n_estimators': 10}   \n",
       "1               3                 20     {'max_depth': 3, 'n_estimators': 20}   \n",
       "2               3                 30     {'max_depth': 3, 'n_estimators': 30}   \n",
       "3               5                 10     {'max_depth': 5, 'n_estimators': 10}   \n",
       "4               5                 20     {'max_depth': 5, 'n_estimators': 20}   \n",
       "5               5                 30     {'max_depth': 5, 'n_estimators': 30}   \n",
       "6            None                 10  {'max_depth': None, 'n_estimators': 10}   \n",
       "7            None                 20  {'max_depth': None, 'n_estimators': 20}   \n",
       "8            None                 30  {'max_depth': None, 'n_estimators': 30}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0         -57.053072         -58.597543         -57.800953         -56.302221   \n",
       "1         -56.114301         -58.379012         -57.611873         -55.796353   \n",
       "2         -56.795244         -58.360240         -57.675368         -55.595180   \n",
       "3         -47.771095         -50.148158         -49.530197         -48.060286   \n",
       "4         -47.463595         -49.881751         -49.425932         -48.484807   \n",
       "5         -47.566988         -49.791238         -49.260329         -48.009273   \n",
       "6         -35.867558         -36.525082         -36.616488         -35.935589   \n",
       "7         -35.256576         -35.265678         -35.323813         -34.457095   \n",
       "8         -33.915970         -34.911443         -35.463030         -34.104623   \n",
       "\n",
       "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0         -56.377458        57.226250        0.873498                9  \n",
       "1         -57.423307        57.064969        0.966165                7  \n",
       "2         -57.098016        57.104810        0.924825                8  \n",
       "3         -48.718490        48.845645        0.889131                6  \n",
       "4         -48.158451        48.682907        0.870670                5  \n",
       "5         -47.973601        48.520286        0.852263                4  \n",
       "6         -36.145070        36.217957        0.303637                3  \n",
       "7         -34.563372        34.973307        0.380289                2  \n",
       "8         -33.879657        34.454945        0.627503                1  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_max_depth</th>\n      <th>param_n_estimators</th>\n      <th>params</th>\n      <th>split0_test_score</th>\n      <th>split1_test_score</th>\n      <th>split2_test_score</th>\n      <th>split3_test_score</th>\n      <th>split4_test_score</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.114995</td>\n      <td>0.009190</td>\n      <td>0.009202</td>\n      <td>0.000751</td>\n      <td>3</td>\n      <td>10</td>\n      <td>{'max_depth': 3, 'n_estimators': 10}</td>\n      <td>-57.053072</td>\n      <td>-58.597543</td>\n      <td>-57.800953</td>\n      <td>-56.302221</td>\n      <td>-56.377458</td>\n      <td>57.226250</td>\n      <td>0.873498</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.214003</td>\n      <td>0.006692</td>\n      <td>0.011596</td>\n      <td>0.001356</td>\n      <td>3</td>\n      <td>20</td>\n      <td>{'max_depth': 3, 'n_estimators': 20}</td>\n      <td>-56.114301</td>\n      <td>-58.379012</td>\n      <td>-57.611873</td>\n      <td>-55.796353</td>\n      <td>-57.423307</td>\n      <td>57.064969</td>\n      <td>0.966165</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.315399</td>\n      <td>0.013982</td>\n      <td>0.012401</td>\n      <td>0.001020</td>\n      <td>3</td>\n      <td>30</td>\n      <td>{'max_depth': 3, 'n_estimators': 30}</td>\n      <td>-56.795244</td>\n      <td>-58.360240</td>\n      <td>-57.675368</td>\n      <td>-55.595180</td>\n      <td>-57.098016</td>\n      <td>57.104810</td>\n      <td>0.924825</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.165599</td>\n      <td>0.006651</td>\n      <td>0.008600</td>\n      <td>0.000490</td>\n      <td>5</td>\n      <td>10</td>\n      <td>{'max_depth': 5, 'n_estimators': 10}</td>\n      <td>-47.771095</td>\n      <td>-50.148158</td>\n      <td>-49.530197</td>\n      <td>-48.060286</td>\n      <td>-48.718490</td>\n      <td>48.845645</td>\n      <td>0.889131</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.329000</td>\n      <td>0.007459</td>\n      <td>0.010801</td>\n      <td>0.000747</td>\n      <td>5</td>\n      <td>20</td>\n      <td>{'max_depth': 5, 'n_estimators': 20}</td>\n      <td>-47.463595</td>\n      <td>-49.881751</td>\n      <td>-49.425932</td>\n      <td>-48.484807</td>\n      <td>-48.158451</td>\n      <td>48.682907</td>\n      <td>0.870670</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.503401</td>\n      <td>0.015906</td>\n      <td>0.013999</td>\n      <td>0.001266</td>\n      <td>5</td>\n      <td>30</td>\n      <td>{'max_depth': 5, 'n_estimators': 30}</td>\n      <td>-47.566988</td>\n      <td>-49.791238</td>\n      <td>-49.260329</td>\n      <td>-48.009273</td>\n      <td>-47.973601</td>\n      <td>48.520286</td>\n      <td>0.852263</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.479598</td>\n      <td>0.012811</td>\n      <td>0.011999</td>\n      <td>0.001097</td>\n      <td>None</td>\n      <td>10</td>\n      <td>{'max_depth': None, 'n_estimators': 10}</td>\n      <td>-35.867558</td>\n      <td>-36.525082</td>\n      <td>-36.616488</td>\n      <td>-35.935589</td>\n      <td>-36.145070</td>\n      <td>36.217957</td>\n      <td>0.303637</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.919997</td>\n      <td>0.010991</td>\n      <td>0.017801</td>\n      <td>0.000750</td>\n      <td>None</td>\n      <td>20</td>\n      <td>{'max_depth': None, 'n_estimators': 20}</td>\n      <td>-35.256576</td>\n      <td>-35.265678</td>\n      <td>-35.323813</td>\n      <td>-34.457095</td>\n      <td>-34.563372</td>\n      <td>34.973307</td>\n      <td>0.380289</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1.366801</td>\n      <td>0.035571</td>\n      <td>0.023400</td>\n      <td>0.000800</td>\n      <td>None</td>\n      <td>30</td>\n      <td>{'max_depth': None, 'n_estimators': 30}</td>\n      <td>-33.915970</td>\n      <td>-34.911443</td>\n      <td>-35.463030</td>\n      <td>-34.104623</td>\n      <td>-33.879657</td>\n      <td>34.454945</td>\n      <td>0.627503</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [10, 20, 30],\n",
    "    \"max_depth\": [3, 5, None],\n",
    "}\n",
    "grid_search = GridSearchCV(\n",
    "    RandomForestRegressor(n_jobs=2), param_grid=param_grid,\n",
    "    scoring=\"neg_mean_absolute_error\", n_jobs=2,\n",
    ")\n",
    "grid_search.fit(data_train, target_train)\n",
    "\n",
    "columns = [f\"param_{name}\" for name in param_grid.keys()]\n",
    "columns += [\"mean_test_score\", \"rank_test_score\"]\n",
    "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "cv_results[\"mean_test_score\"] = -cv_results[\"mean_test_score\"]\n",
    "cv_results[columns].sort_values(by=\"rank_test_score\")\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that in our grid-search, the largest `max_depth` together\n",
    "with the largest `n_estimators` led to the best statistical performance.\n",
    "\n",
    "## Gradient-boosting decision trees\n",
    "\n",
    "For gradient-boosting, parameters are coupled, so we cannot set the\n",
    "parameters one after the other anymore. The important parameters are\n",
    "`n_estimators`, `max_depth`, and `learning_rate`.\n",
    "\n",
    "Let's first discuss the `max_depth` parameter.\n",
    "We saw in the section on gradient-boosting that the algorithm fits the error\n",
    "of the previous tree in the ensemble. Thus, fitting fully grown trees will\n",
    "be detrimental.\n",
    "Indeed, the first tree of the ensemble would perfectly fit (overfit) the data\n",
    "and thus no subsequent tree would be required, since there would be no\n",
    "residuals.\n",
    "Therefore, the tree used in gradient-boosting should have a low depth,\n",
    "typically between 3 to 8 levels. Having very weak learners at each step will\n",
    "help reducing overfitting.\n",
    "\n",
    "With this consideration in mind, the deeper the trees, the faster the\n",
    "residuals will be corrected and less learners are required. Therefore,\n",
    "`n_estimators` should be increased if `max_depth` is lower.\n",
    "\n",
    "Finally, we have overlooked the impact of the `learning_rate` parameter\n",
    "until now. When fitting the residuals, we would like the tree\n",
    "to try to correct all possible errors or only a fraction of them.\n",
    "The learning-rate allows you to control this behaviour.\n",
    "A small learning-rate value would only correct the residuals of very few\n",
    "samples. If a large learning-rate is set (e.g., 1), we would fit the\n",
    "residuals of all samples. So, with a very low learning-rate, we will need\n",
    "more estimators to correct the overall error. However, a too large\n",
    "learning-rate tends to obtain an overfitted ensemble,\n",
    "similar to having a too large tree depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.265198      0.008422         0.002802        0.000401   \n",
       "1        0.770600      0.022721         0.004208        0.000399   \n",
       "2        1.256007      0.008301         0.004799        0.000401   \n",
       "3        0.424797      0.017061         0.003004        0.000008   \n",
       "4        1.290594      0.022702         0.005804        0.000403   \n",
       "5        2.152998      0.021054         0.007609        0.000496   \n",
       "6        1.312402      0.017751         0.012394        0.001016   \n",
       "7        3.923599      0.035425         0.030592        0.001748   \n",
       "8        6.545005      0.080264         0.050996        0.002960   \n",
       "9        0.254803      0.004206         0.003000        0.000014   \n",
       "10       0.806593      0.057779         0.003600        0.000799   \n",
       "11       1.379998      0.037819         0.005003        0.001100   \n",
       "12       0.438203      0.009601         0.003398        0.000803   \n",
       "13       1.267598      0.009699         0.004805        0.000404   \n",
       "14       2.105003      0.009962         0.006201        0.000988   \n",
       "15       0.362200      0.032708         0.003808        0.000748   \n",
       "16       0.362402      0.039861         0.003999        0.000627   \n",
       "17       0.357197      0.035309         0.003799        0.000400   \n",
       "\n",
       "   param_learning_rate param_max_depth param_n_estimators  \\\n",
       "0                  0.1               3                 10   \n",
       "1                  0.1               3                 30   \n",
       "2                  0.1               3                 50   \n",
       "3                  0.1               5                 10   \n",
       "4                  0.1               5                 30   \n",
       "5                  0.1               5                 50   \n",
       "6                  0.1            None                 10   \n",
       "7                  0.1            None                 30   \n",
       "8                  0.1            None                 50   \n",
       "9                    1               3                 10   \n",
       "10                   1               3                 30   \n",
       "11                   1               3                 50   \n",
       "12                   1               5                 10   \n",
       "13                   1               5                 30   \n",
       "14                   1               5                 50   \n",
       "15                   1            None                 10   \n",
       "16                   1            None                 30   \n",
       "17                   1            None                 50   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'learning_rate': 0.1, 'max_depth': 3, 'n_esti...         -62.364708   \n",
       "1   {'learning_rate': 0.1, 'max_depth': 3, 'n_esti...         -45.702805   \n",
       "2   {'learning_rate': 0.1, 'max_depth': 3, 'n_esti...         -40.487300   \n",
       "3   {'learning_rate': 0.1, 'max_depth': 5, 'n_esti...         -56.193186   \n",
       "4   {'learning_rate': 0.1, 'max_depth': 5, 'n_esti...         -39.072257   \n",
       "5   {'learning_rate': 0.1, 'max_depth': 5, 'n_esti...         -35.660472   \n",
       "6   {'learning_rate': 0.1, 'max_depth': None, 'n_e...         -50.522126   \n",
       "7   {'learning_rate': 0.1, 'max_depth': None, 'n_e...         -43.819124   \n",
       "8   {'learning_rate': 0.1, 'max_depth': None, 'n_e...         -44.276096   \n",
       "9   {'learning_rate': 1, 'max_depth': 3, 'n_estima...         -41.792262   \n",
       "10  {'learning_rate': 1, 'max_depth': 3, 'n_estima...         -37.716744   \n",
       "11  {'learning_rate': 1, 'max_depth': 3, 'n_estima...         -36.955203   \n",
       "12  {'learning_rate': 1, 'max_depth': 5, 'n_estima...         -40.387070   \n",
       "13  {'learning_rate': 1, 'max_depth': 5, 'n_estima...         -39.585551   \n",
       "14  {'learning_rate': 1, 'max_depth': 5, 'n_estima...         -40.221176   \n",
       "15  {'learning_rate': 1, 'max_depth': None, 'n_est...         -46.334182   \n",
       "16  {'learning_rate': 1, 'max_depth': None, 'n_est...         -45.576204   \n",
       "17  {'learning_rate': 1, 'max_depth': None, 'n_est...         -45.633797   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0          -63.018525         -62.717368         -61.494593   \n",
       "1          -45.658183         -46.333430         -45.422513   \n",
       "2          -40.566135         -41.350029         -39.726453   \n",
       "3          -56.849927         -57.125894         -55.503329   \n",
       "4          -39.230976         -40.373662         -38.671351   \n",
       "5          -35.559785         -35.950855         -35.278674   \n",
       "6          -52.479864         -52.346886         -53.133086   \n",
       "7          -46.045101         -45.143224         -47.325040   \n",
       "8          -46.195607         -45.380421         -47.647399   \n",
       "9          -41.845149         -41.636437         -41.129701   \n",
       "10         -37.636388         -37.889548         -37.394267   \n",
       "11         -36.928152         -37.578155         -36.428255   \n",
       "12         -40.413606         -38.333784         -39.312546   \n",
       "13         -40.292860         -37.873249         -39.054052   \n",
       "14         -40.632602         -38.924791         -39.901374   \n",
       "15         -47.331279         -46.810834         -48.841030   \n",
       "16         -47.902274         -46.796459         -48.981437   \n",
       "17         -47.551012         -47.168518         -48.783602   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0          -61.756145        62.270268        0.571787               18  \n",
       "1          -45.663489        45.756084        0.305154               11  \n",
       "2          -40.878545        40.601692        0.532363                8  \n",
       "3          -56.105335        56.355534        0.574994               17  \n",
       "4          -39.462528        39.362155        0.567746                5  \n",
       "5          -35.777638        35.645485        0.224871                1  \n",
       "6          -51.511882        51.998769        0.900760               16  \n",
       "7          -45.711275        45.608753        1.145953               10  \n",
       "8          -45.839419        45.867788        1.099663               12  \n",
       "9          -41.607325        41.602175        0.252824                9  \n",
       "10         -36.676685        37.462726        0.424124                3  \n",
       "11         -35.640968        36.706147        0.645530                2  \n",
       "12         -38.661997        39.421801        0.858888                6  \n",
       "13         -38.698338        39.100810        0.815724                4  \n",
       "14         -39.867914        39.909571        0.564175                7  \n",
       "15         -48.028170        47.469099        0.887141               15  \n",
       "16         -47.521872        47.355649        1.135670               14  \n",
       "17         -47.388925        47.305171        1.006517               13  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_learning_rate</th>\n      <th>param_max_depth</th>\n      <th>param_n_estimators</th>\n      <th>params</th>\n      <th>split0_test_score</th>\n      <th>split1_test_score</th>\n      <th>split2_test_score</th>\n      <th>split3_test_score</th>\n      <th>split4_test_score</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.265198</td>\n      <td>0.008422</td>\n      <td>0.002802</td>\n      <td>0.000401</td>\n      <td>0.1</td>\n      <td>3</td>\n      <td>10</td>\n      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_esti...</td>\n      <td>-62.364708</td>\n      <td>-63.018525</td>\n      <td>-62.717368</td>\n      <td>-61.494593</td>\n      <td>-61.756145</td>\n      <td>62.270268</td>\n      <td>0.571787</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.770600</td>\n      <td>0.022721</td>\n      <td>0.004208</td>\n      <td>0.000399</td>\n      <td>0.1</td>\n      <td>3</td>\n      <td>30</td>\n      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_esti...</td>\n      <td>-45.702805</td>\n      <td>-45.658183</td>\n      <td>-46.333430</td>\n      <td>-45.422513</td>\n      <td>-45.663489</td>\n      <td>45.756084</td>\n      <td>0.305154</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.256007</td>\n      <td>0.008301</td>\n      <td>0.004799</td>\n      <td>0.000401</td>\n      <td>0.1</td>\n      <td>3</td>\n      <td>50</td>\n      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_esti...</td>\n      <td>-40.487300</td>\n      <td>-40.566135</td>\n      <td>-41.350029</td>\n      <td>-39.726453</td>\n      <td>-40.878545</td>\n      <td>40.601692</td>\n      <td>0.532363</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.424797</td>\n      <td>0.017061</td>\n      <td>0.003004</td>\n      <td>0.000008</td>\n      <td>0.1</td>\n      <td>5</td>\n      <td>10</td>\n      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n      <td>-56.193186</td>\n      <td>-56.849927</td>\n      <td>-57.125894</td>\n      <td>-55.503329</td>\n      <td>-56.105335</td>\n      <td>56.355534</td>\n      <td>0.574994</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.290594</td>\n      <td>0.022702</td>\n      <td>0.005804</td>\n      <td>0.000403</td>\n      <td>0.1</td>\n      <td>5</td>\n      <td>30</td>\n      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n      <td>-39.072257</td>\n      <td>-39.230976</td>\n      <td>-40.373662</td>\n      <td>-38.671351</td>\n      <td>-39.462528</td>\n      <td>39.362155</td>\n      <td>0.567746</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2.152998</td>\n      <td>0.021054</td>\n      <td>0.007609</td>\n      <td>0.000496</td>\n      <td>0.1</td>\n      <td>5</td>\n      <td>50</td>\n      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n      <td>-35.660472</td>\n      <td>-35.559785</td>\n      <td>-35.950855</td>\n      <td>-35.278674</td>\n      <td>-35.777638</td>\n      <td>35.645485</td>\n      <td>0.224871</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1.312402</td>\n      <td>0.017751</td>\n      <td>0.012394</td>\n      <td>0.001016</td>\n      <td>0.1</td>\n      <td>None</td>\n      <td>10</td>\n      <td>{'learning_rate': 0.1, 'max_depth': None, 'n_e...</td>\n      <td>-50.522126</td>\n      <td>-52.479864</td>\n      <td>-52.346886</td>\n      <td>-53.133086</td>\n      <td>-51.511882</td>\n      <td>51.998769</td>\n      <td>0.900760</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>3.923599</td>\n      <td>0.035425</td>\n      <td>0.030592</td>\n      <td>0.001748</td>\n      <td>0.1</td>\n      <td>None</td>\n      <td>30</td>\n      <td>{'learning_rate': 0.1, 'max_depth': None, 'n_e...</td>\n      <td>-43.819124</td>\n      <td>-46.045101</td>\n      <td>-45.143224</td>\n      <td>-47.325040</td>\n      <td>-45.711275</td>\n      <td>45.608753</td>\n      <td>1.145953</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>6.545005</td>\n      <td>0.080264</td>\n      <td>0.050996</td>\n      <td>0.002960</td>\n      <td>0.1</td>\n      <td>None</td>\n      <td>50</td>\n      <td>{'learning_rate': 0.1, 'max_depth': None, 'n_e...</td>\n      <td>-44.276096</td>\n      <td>-46.195607</td>\n      <td>-45.380421</td>\n      <td>-47.647399</td>\n      <td>-45.839419</td>\n      <td>45.867788</td>\n      <td>1.099663</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.254803</td>\n      <td>0.004206</td>\n      <td>0.003000</td>\n      <td>0.000014</td>\n      <td>1</td>\n      <td>3</td>\n      <td>10</td>\n      <td>{'learning_rate': 1, 'max_depth': 3, 'n_estima...</td>\n      <td>-41.792262</td>\n      <td>-41.845149</td>\n      <td>-41.636437</td>\n      <td>-41.129701</td>\n      <td>-41.607325</td>\n      <td>41.602175</td>\n      <td>0.252824</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.806593</td>\n      <td>0.057779</td>\n      <td>0.003600</td>\n      <td>0.000799</td>\n      <td>1</td>\n      <td>3</td>\n      <td>30</td>\n      <td>{'learning_rate': 1, 'max_depth': 3, 'n_estima...</td>\n      <td>-37.716744</td>\n      <td>-37.636388</td>\n      <td>-37.889548</td>\n      <td>-37.394267</td>\n      <td>-36.676685</td>\n      <td>37.462726</td>\n      <td>0.424124</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>1.379998</td>\n      <td>0.037819</td>\n      <td>0.005003</td>\n      <td>0.001100</td>\n      <td>1</td>\n      <td>3</td>\n      <td>50</td>\n      <td>{'learning_rate': 1, 'max_depth': 3, 'n_estima...</td>\n      <td>-36.955203</td>\n      <td>-36.928152</td>\n      <td>-37.578155</td>\n      <td>-36.428255</td>\n      <td>-35.640968</td>\n      <td>36.706147</td>\n      <td>0.645530</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.438203</td>\n      <td>0.009601</td>\n      <td>0.003398</td>\n      <td>0.000803</td>\n      <td>1</td>\n      <td>5</td>\n      <td>10</td>\n      <td>{'learning_rate': 1, 'max_depth': 5, 'n_estima...</td>\n      <td>-40.387070</td>\n      <td>-40.413606</td>\n      <td>-38.333784</td>\n      <td>-39.312546</td>\n      <td>-38.661997</td>\n      <td>39.421801</td>\n      <td>0.858888</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>1.267598</td>\n      <td>0.009699</td>\n      <td>0.004805</td>\n      <td>0.000404</td>\n      <td>1</td>\n      <td>5</td>\n      <td>30</td>\n      <td>{'learning_rate': 1, 'max_depth': 5, 'n_estima...</td>\n      <td>-39.585551</td>\n      <td>-40.292860</td>\n      <td>-37.873249</td>\n      <td>-39.054052</td>\n      <td>-38.698338</td>\n      <td>39.100810</td>\n      <td>0.815724</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>2.105003</td>\n      <td>0.009962</td>\n      <td>0.006201</td>\n      <td>0.000988</td>\n      <td>1</td>\n      <td>5</td>\n      <td>50</td>\n      <td>{'learning_rate': 1, 'max_depth': 5, 'n_estima...</td>\n      <td>-40.221176</td>\n      <td>-40.632602</td>\n      <td>-38.924791</td>\n      <td>-39.901374</td>\n      <td>-39.867914</td>\n      <td>39.909571</td>\n      <td>0.564175</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0.362200</td>\n      <td>0.032708</td>\n      <td>0.003808</td>\n      <td>0.000748</td>\n      <td>1</td>\n      <td>None</td>\n      <td>10</td>\n      <td>{'learning_rate': 1, 'max_depth': None, 'n_est...</td>\n      <td>-46.334182</td>\n      <td>-47.331279</td>\n      <td>-46.810834</td>\n      <td>-48.841030</td>\n      <td>-48.028170</td>\n      <td>47.469099</td>\n      <td>0.887141</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0.362402</td>\n      <td>0.039861</td>\n      <td>0.003999</td>\n      <td>0.000627</td>\n      <td>1</td>\n      <td>None</td>\n      <td>30</td>\n      <td>{'learning_rate': 1, 'max_depth': None, 'n_est...</td>\n      <td>-45.576204</td>\n      <td>-47.902274</td>\n      <td>-46.796459</td>\n      <td>-48.981437</td>\n      <td>-47.521872</td>\n      <td>47.355649</td>\n      <td>1.135670</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>0.357197</td>\n      <td>0.035309</td>\n      <td>0.003799</td>\n      <td>0.000400</td>\n      <td>1</td>\n      <td>None</td>\n      <td>50</td>\n      <td>{'learning_rate': 1, 'max_depth': None, 'n_est...</td>\n      <td>-45.633797</td>\n      <td>-47.551012</td>\n      <td>-47.168518</td>\n      <td>-48.783602</td>\n      <td>-47.388925</td>\n      <td>47.305171</td>\n      <td>1.006517</td>\n      <td>13</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [10, 30, 50],\n",
    "    \"max_depth\": [3, 5, None],\n",
    "    \"learning_rate\": [0.1, 1],\n",
    "}\n",
    "grid_search = GridSearchCV(\n",
    "    GradientBoostingRegressor(), param_grid=param_grid,\n",
    "    scoring=\"neg_mean_absolute_error\", n_jobs=2\n",
    ")\n",
    "grid_search.fit(data_train, target_train)\n",
    "\n",
    "columns = [f\"param_{name}\" for name in param_grid.keys()]\n",
    "columns += [\"mean_test_score\", \"rank_test_score\"]\n",
    "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "cv_results[\"mean_test_score\"] = -cv_results[\"mean_test_score\"]\n",
    "cv_results[columns].sort_values(by=\"rank_test_score\")\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition caution alert alert-warning\">\n",
    "<p class=\"first admonition-title\" style=\"font-weight: bold;\">Caution!</p>\n",
    "<p class=\"last\">Here, we tune the <tt class=\"docutils literal\">n_estimators</tt> but be aware that using early-stopping as\n",
    "in the previous exercise will be better.</p>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit ('Python39')"
  },
  "interpreter": {
   "hash": "effe5469eba6e2b1ac8a7bf67c428998281de374b9fe83a2f672f89c7077779b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}