{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "effe5469eba6e2b1ac8a7bf67c428998281de374b9fe83a2f672f89c7077779b"
   }
  },
  "interpreter": {
   "hash": "effe5469eba6e2b1ac8a7bf67c428998281de374b9fe83a2f672f89c7077779b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Module 6 : Wrap up Quizzzzzzz"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Open the dataset blood_transfusion.csv.\n",
    "```\n",
    "import pandas as pd\n",
    "\n",
    "blood_transfusion = pd.read_csv(\"../datasets/blood_transfusion.csv\")\n",
    "data = blood_transfusion.drop(columns=\"Class\")\n",
    "target = blood_transfusion[\"Class\"]\n",
    "```\n",
    "In this dataset, the column \"Class\" is the target vector containing the labels that our model should predict.\n",
    "\n",
    "For all the questions below, make a cross-validation evaluation using a 10-fold cross-validation strategy.\n",
    "\n",
    "Evaluate the performance of a sklearn.dummy.DummyClassifier that always predict the most frequent class seen during the training. Be aware that you can pass a list of score to compute in sklearn.model_selection.cross_validate by setting the parameter scoring.\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(     Recency  Frequency  Monetary  Time\n",
       " 0          2         50     12500    98\n",
       " 1          0         13      3250    28\n",
       " 2          1         16      4000    35\n",
       " 3          2         20      5000    45\n",
       " 4          1         24      6000    77\n",
       " ..       ...        ...       ...   ...\n",
       " 743       23          2       500    38\n",
       " 744       21          2       500    52\n",
       " 745       23          3       750    62\n",
       " 746       39          1       250    39\n",
       " 747       72          1       250    72\n",
       " \n",
       " [748 rows x 4 columns],\n",
       " 0          donated\n",
       " 1          donated\n",
       " 2          donated\n",
       " 3          donated\n",
       " 4      not donated\n",
       "           ...     \n",
       " 743    not donated\n",
       " 744    not donated\n",
       " 745    not donated\n",
       " 746    not donated\n",
       " 747    not donated\n",
       " Name: Class, Length: 748, dtype: object)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "blood_transfusion = pd.read_csv(\"../datasets/blood_transfusion.csv\")\n",
    "data = blood_transfusion.drop(columns=\"Class\")\n",
    "target = blood_transfusion[\"Class\"]\n",
    "data, target"
   ]
  },
  {
   "source": [
    "#### Question 1\n",
    "\n",
    "What the accuracy of this dummy classifier?\n",
    "\n",
    " a) ~0.5  \n",
    " b) ~0.62  \n",
    " c) ~0.75\n",
    "\n",
    " C'est la c)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7620320855614974"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "## Mon code\n",
    "dummy = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy.fit(data, target)\n",
    "dummy.score(data, target)\n",
    "\n",
    "# target.value_counts(normalize=True)\n"
   ]
  },
  {
   "source": [
    "#### What the balanced accuracy of this dummy classifier?\n",
    "\n",
    " a) ~0.5  \n",
    " b) ~0.62  \n",
    " c) ~0.75\n",
    "\n",
    " Ba la b)\n",
    " "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Average accuracy: 0.762\nAverage balanced accuracy: 0.500\n"
     ]
    }
   ],
   "source": [
    "dummy = DummyClassifier(strategy=\"most_frequent\")\n",
    "cv_results = cross_validate(dummy, data, target, cv=10, scoring=[\"accuracy\", \"balanced_accuracy\"])\n",
    "\n",
    "print(f\"Average accuracy: {cv_results['test_accuracy'].mean():.3f}\")\n",
    "print(f\"Average balanced accuracy: \"\n",
    "      f\"{cv_results['test_balanced_accuracy'].mean():.3f}\")"
   ]
  },
  {
   "source": [
    "#### Question 3 (1 point possible)\n",
    "Replace the DummyClassifier by a sklearn.tree.DecisionTreeClassifier and check the statistical performance to answer the question below.\n",
    "\n",
    "Is a single decision classifier better than a dummy classifier, by an increase of at least 0.04 of the balanced accuracy?\n",
    "\n",
    " a) Yes  \n",
    " b) No\n",
    "\n",
    " Je dirais non !\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy de l'arbre de décision de 0.626\nBalanced accuracy de l'arbre de décision de 0.506\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "cv_results = cross_validate(tree, data, target, cv=10, scoring=[\"accuracy\", \"balanced_accuracy\"])\n",
    "# print(f\"Score de l'arbre de décision de {cv_results['test_score'].mean():.2f}\")\n",
    "print(f\"Accuracy de l'arbre de décision de {cv_results['test_accuracy'].mean():.3f}\")\n",
    "print(f\"Balanced accuracy de l'arbre de décision de {cv_results['test_balanced_accuracy'].mean():.3f}\")\n"
   ]
  },
  {
   "source": [
    "#### Question 4 (1 point possible)\n",
    "Evaluate the performance of a sklearn.ensemble.RandomForestClassifier using 300 trees.\n",
    "\n",
    "Is random forest better than a dummy classifier, by an increase of at least 0.04 of the balanced accuracy?\n",
    "\n",
    " a) Yes  \n",
    " b) No\n",
    "\n",
    " Non !"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy de l'arbre de décision de 0.667\nBalanced accuracy de la forêt aléatoire de 0.529\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=300)\n",
    "cv_results = cross_validate(forest, data, target, cv=10, scoring=[\"accuracy\", \"balanced_accuracy\"])\n",
    "print(f\"Accuracy de l'arbre de décision de {cv_results['test_accuracy'].mean():.3f}\")\n",
    "print(f\"Balanced accuracy de la forêt aléatoire de {cv_results['test_balanced_accuracy'].mean():.3f}\")"
   ]
  },
  {
   "source": [
    "#### Question 5 (1 point possible)\n",
    "Compare a sklearn.ensemble.GradientBoostingClassifier and a sklearn.ensemble.RandomForestClassifier with both 300 trees.\n",
    "To do so, repeat 10 times a 10-fold cross-validation by using the balanced accuracy as metric. For each of the ten try, compute the average of the cross-validation score for both models. Count how many times a model is better than the other.\n",
    "\n",
    "On average, is the gradient boosting better than the random forest?\n",
    "\n",
    " a) Yes  \n",
    " b) No  \n",
    " c) Equivalent\n",
    "\n",
    " Je dirais a)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test #1 : Random forest : 0.530 and Gradient Boosting : 0.536\n",
      "Test #2 : Random forest : 0.526 and Gradient Boosting : 0.537\n",
      "Test #3 : Random forest : 0.523 and Gradient Boosting : 0.536\n",
      "Test #4 : Random forest : 0.535 and Gradient Boosting : 0.536\n",
      "Test #5 : Random forest : 0.533 and Gradient Boosting : 0.536\n",
      "Test #6 : Random forest : 0.529 and Gradient Boosting : 0.536\n",
      "Test #7 : Random forest : 0.531 and Gradient Boosting : 0.536\n",
      "Test #8 : Random forest : 0.528 and Gradient Boosting : 0.536\n",
      "Test #9 : Random forest : 0.526 and Gradient Boosting : 0.536\n",
      "Test #10 : Random forest : 0.531 and Gradient Boosting : 0.536\n",
      "Le Gradient Boosting a été plus efficace que la Random Forest 10 fois\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "mean_tree, mean_gradient = [], []\n",
    "for i in range(10):\n",
    "    random_tree = RandomForestClassifier(n_estimators=300)\n",
    "    gradient_boosting = GradientBoostingClassifier(n_estimators=300)\n",
    "    cv_tree = cross_validate(random_tree, data, target, cv=10, scoring=\"balanced_accuracy\")\n",
    "    cv_gradient = cross_validate(gradient_boosting, data, target, cv=10, scoring=\"balanced_accuracy\")\n",
    "    print(f\"Test #{i+1} : Random forest : {cv_tree['test_score'].mean():.3f} and Gradient Boosting : {cv_gradient['test_score'].mean():.3f}\")\n",
    "\n",
    "    mean_tree.append(cv_tree['test_score'].mean())\n",
    "    mean_gradient.append(cv_gradient['test_score'].mean())\n",
    "\n",
    "compare = [g > t for g, t in zip(mean_gradient, mean_tree)]\n",
    "print(f\"Le Gradient Boosting a été plus efficace que la Random Forest {sum(compare)} fois\")"
   ]
  },
  {
   "source": [
    "Evaluate the performance of a sklearn.ensemble.HistGradientBoostingClassifier. Enable early-stopping and add as many trees as needed.\n",
    "\n",
    "Note: Be aware that you need a specific import when importing the HistGradientBoostingClassifier:\n",
    "```\n",
    "# explicitly require this experimental feature\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "# now you can import normally from ensemble\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "```\n",
    "\n",
    "#### Question 6 (1 point possible)\n",
    "Is histogram gradient boosting a better classifier considering the mean of the cross-validation test score?\n",
    "\n",
    " a) Histogram gradient boosting is the best estimator  \n",
    " b) Histogram gradient boosting is better than random forest but worse than the exact gradient boosting  \n",
    " c) Histogram gradient boosting is better than the exact gradient boosting but worse than the random forest  \n",
    " d) Histogram gradient boosting is the worst estimator\n",
    "\n",
    " C'est la a) (57%)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5731166150670794"
      ]
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "source": [
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "hgb = HistGradientBoostingClassifier(max_iter=10000, early_stopping=True)\n",
    "cv_results = cross_validate(hgb, data, target, cv=10, scoring=\"balanced_accuracy\")\n",
    "cv_results[\"test_score\"].mean()\n"
   ]
  },
  {
   "source": [
    "#### Question 7 (1 point possible)\n",
    "With the early stopping activated, how many trees on average the HistGradientBoostingClassifier needed to converge?\n",
    "\n",
    " a) ~30  \n",
    " b) ~100  \n",
    " c) ~150  \n",
    " d) ~200  \n",
    " e) ~300\n",
    "\n",
    " C'est a)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "18 arbres utilisés avant early stopping\n20 arbres utilisés avant early stopping\n22 arbres utilisés avant early stopping\n47 arbres utilisés avant early stopping\n34 arbres utilisés avant early stopping\n33 arbres utilisés avant early stopping\n48 arbres utilisés avant early stopping\n25 arbres utilisés avant early stopping\n14 arbres utilisés avant early stopping\n17 arbres utilisés avant early stopping\n27.8 arbres utilisés en moyenne \n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "hgb = HistGradientBoostingClassifier(max_iter=10000, early_stopping=True)\n",
    "cv_results = cross_validate(hgb, data, target, cv=10, scoring=\"balanced_accuracy\", return_estimator=True)\n",
    "\n",
    "for est in cv_results[\"estimator\"]:\n",
    "    print(f\"{est.n_iter_} arbres utilisés avant early stopping\")\n",
    "print(f\"{np.mean([est.n_iter_ for est in cv_results['estimator']])} arbres utilisés en moyenne \")"
   ]
  },
  {
   "source": [
    "Imbalanced-learn is an open-source library relying on scikit-learn and provides methods to deal with classification with imbalanced classes.\n",
    "\n",
    "Here, we will be using the class imblearn.ensemble.BalancedBaggingClassifier to alleviate the issue of class imbalance.\n",
    "\n",
    "Use the BalancedBaggingClassifier and pass an HistGradientBoostingClassifier as a base_estimator. Fix the hyperparameter n_estimators to 50.\n",
    "#### Question 8 (1 point possible)\n",
    "What is a BalancedBaggingClassifier?\n",
    "\n",
    " a) Is a classifier that make sure that each tree leaves belong to the same depth level   \n",
    " b) Is a classifier that explicitly maximizes the balanced accuracy score   \n",
    " c) Equivalent to a sklearn.ensemble.BaggingClassifier with a resampling of each bootstrap sample to contain a many samples from each class.\n",
    "\n",
    " D'après la [doc](https://imbalanced-learn.org/stable/ensemble.html#bagging), c'est la c)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### Question 9 (1 point possible)\n",
    "Compared to the balanced accuracy of a HistGradientBoostingClassifier alone (computed in one of the previous questions), the balanced accuracy of the BalancedBaggingClassifier is:\n",
    "\n",
    " a) Worse  \n",
    " b) Better  \n",
    " c) Equivalent\n",
    "\n",
    " Better !!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6045751633986928"
      ]
     },
     "metadata": {},
     "execution_count": 80
    }
   ],
   "source": [
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "\n",
    "bbc = BalancedBaggingClassifier(base_estimator=HistGradientBoostingClassifier(max_iter=10000, early_stopping=True), n_estimators=50)\n",
    "cv_results = cross_validate(bbc, data, target, cv=10, scoring=\"balanced_accuracy\")\n",
    "cv_results[\"test_score\"].mean()"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}